{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f911b47",
   "metadata": {},
   "source": [
    "# Model Optimization\n",
    "**Project Assumption:** The target model is SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d4524",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "1. Data Loading\n",
    "    - 1.1 Library Import\n",
    "    - 1.2 Data Loading\n",
    "2. Strategy Selection: Rapid Prototyping\n",
    "    - 2.1 Generating a Stratified Subset (5,000 samples)\n",
    "    - 2.2 Helper FUnctions for Training and Testing\n",
    "    - 2.3 Baseline Model\n",
    "    - 2.4 Weighted Loss (Class Weight = 'Balanced')\n",
    "    - 2.5 UnderSampling 1:1\n",
    "    - 2.6 UnderSampling 2:1\n",
    "    - 2.7 UnderSampling 10:3\n",
    "    - 2.8 UnderSampling 5:1\n",
    "    - 2.9 UnderSampling 2:1 + Balanced\n",
    "    - 2.10 UnderSampling 2:1 + Balanced\n",
    "3. Experimental Results & Model Selection\n",
    "4. Analysis of Suboptimal Model Performance\n",
    "    - 4.1 Training on a Larger Dataset & Thresholf Tuning\n",
    "    - 4.2 Alternative Model - XGBoost\n",
    "    - 4.3 Soft Pipeline\n",
    "    - 4.4 Unethical Pipeline\n",
    "    - 4.5 More Features Pipeline\n",
    "    - 4.6 Very Soft Pipeline\n",
    "    - 4.7 Conclusion\n",
    "5. Model Optimization\n",
    "    - 5.1 Initial Optimization\n",
    "    - 5.2 Extended Hyperparameter Tuning\n",
    "6. The Best Model\n",
    "7. Saving Final Model to the File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c919dd",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f319445b",
   "metadata": {},
   "source": [
    "### 1.1 Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4757653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extension for Scikit-learn* enabled (https://github.com/uxlfoundation/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "import pickle\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, \n",
    "    GridSearchCV, \n",
    "    RandomizedSearchCV\n",
    ")\n",
    "from sklearn.metrics import f1_score, precision_recall_curve\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from pipelines.preprocessing_pipeline import preprocessing_pipeline\n",
    "from pipelines.soft_preprocessing_pipeline import soft_preprocessing_pipeline\n",
    "from pipelines.very_soft_preprocessing_pipeline import very_soft_preprocessing_pipeline\n",
    "from pipelines.unethical_preprocessing_pipeline import unethical_preprocessing_pipeline\n",
    "from pipelines.more_features_preprocessing_pipeline import more_features_preprocessing_pipeline\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363520d1",
   "metadata": {},
   "source": [
    "### 1.2 Data Loading\n",
    "Saving the target encoder to maintain consistency during model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "728d18da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['income_label_encoder.joblib']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_parquet(\"data/train.parquet\")\n",
    "X_train = df_train.drop(columns=['income_50k'])\n",
    "y_train_raw = df_train['income_50k']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train_raw)\n",
    "\n",
    "joblib.dump(le, 'income_label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d5bb0b",
   "metadata": {},
   "source": [
    "## 2. Strategy Selection: Rapid Prototyping\n",
    "\n",
    "Since Support Vector Machines are computationally expensive to train on large datasets, we will perform initial hyperparameter tuning on a **stratified subset of 5,000 rows**.\n",
    "\n",
    "This allows us to:\n",
    "1.  **Iterate quickly:** Test different strategies (e.g., Class Weights, Sampling) and narrow down the range of effective hyperparameters without waiting hours for training\n",
    "2.  **Ensure Reliability:** We utilize **Cross-Validation** to generate trustworthy metrics, ensuring our findings on the subset are robust before applying them to the full dataset\n",
    "3.  **Target the Right Metric:** We set our optimization objective to **Average Precision**. Given the severe class imbalance, Accuracy is misleading (the \"Accuracy Paradox\"), as a model could achieve 94% accuracy simply by predicting the majority class. Optimizing for **Average Precision** forces the model to actively learn the minority class boundaries by balancing Precision and Recall.\n",
    "4. **Fine-Tuning the Prediction Threshold:** Given a solid model, we can adjust the decision threshold to maximize the F1 score.\n",
    "\n",
    "\n",
    "Standard reproducibility is not guaranteed because of the patch_sklearn optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259c90f3",
   "metadata": {},
   "source": [
    "### 2.1 Generating a Stratified Subset (5,000 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c97ab1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset size: (5000, 41)\n",
      "Class distribution in subset:\n",
      "0    0.938\n",
      "1    0.062\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_sub, X_rest, y_sub, y_rest = train_test_split(\n",
    "    X_train, y_train, \n",
    "    train_size=5000, \n",
    "    stratify=y_train,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Subset size: {X_sub.shape}\")\n",
    "print(f\"Class distribution in subset:\\n{pd.Series(y_sub).value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569365f7",
   "metadata": {},
   "source": [
    "### 2.2 Helper Functions for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4db488b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_svm_pipeline(preprocessing_pipeline, sampling_strategy=None, class_weight=None):\n",
    "    steps = preprocessing_pipeline.steps.copy()\n",
    "    \n",
    "    if sampling_strategy is not None:\n",
    "        rus = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=42)\n",
    "        steps.append(('undersampler', rus))\n",
    "\n",
    "    svm = SVC(class_weight=class_weight, probability=True, random_state=42)\n",
    "    steps.append(('svm', svm))\n",
    "\n",
    "    return ImbPipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0190a2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svm_experiment(X, y, preprocessing_pipeline, param_grid, sampling_strategy, title_suffix, class_weight=None):\n",
    "    pipeline = create_svm_pipeline(preprocessing_pipeline, sampling_strategy, class_weight)\n",
    "\n",
    "    scoring_metrics = {\n",
    "        'ROC-AUC': 'roc_auc',\n",
    "        'Accuracy': 'accuracy',\n",
    "        'Precision': 'precision',\n",
    "        'Recall': 'recall',\n",
    "        'F1-Score': 'f1',\n",
    "        'Average Precision': 'average_precision'\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, \n",
    "        param_grid, \n",
    "        cv=3, \n",
    "        scoring=scoring_metrics,\n",
    "        refit='Average Precision', \n",
    "        n_jobs=-1, \n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(f\"\\nRunning Grid Search for {title_suffix}...\")\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    results = grid_search.cv_results_\n",
    "    best_index = grid_search.best_index_\n",
    "\n",
    "    print(f\"\\nðŸ”¹ Best Parameters ({title_suffix}): {grid_search.best_params_}\")\n",
    "\n",
    "    summary_data = []\n",
    "    for metric_name in scoring_metrics.keys():\n",
    "        mean_score = results[f'mean_test_{metric_name}'][best_index]\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Metric': metric_name,\n",
    "            'Mean CV Score': mean_score,\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    pd.options.display.float_format = '{:,.4f}'.format\n",
    "    \n",
    "    print(f\"\\n--- PERFORMANCE REPORT ({title_suffix}) ---\")\n",
    "    display(metrics_df)\n",
    "\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dd2e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "        {\n",
    "            'svm__kernel': ['linear'],\n",
    "            'svm__C': [0.1, 1, 10, 100]\n",
    "        },\n",
    "        {\n",
    "            'svm__kernel': ['rbf'],\n",
    "            'svm__C': [0.1, 1, 10, 100],\n",
    "            'svm__gamma': [0.001, 0.01, 0.1, 1]\n",
    "        }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ce31d4",
   "metadata": {},
   "source": [
    "### 2.3. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fec528c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Grid Search for Baseline...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "ðŸ”¹ Best Parameters (Baseline): {'svm__C': 100, 'svm__gamma': 0.001, 'svm__kernel': 'rbf'}\n",
      "\n",
      "--- PERFORMANCE REPORT (Baseline) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>0.9120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.9464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.8079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.1775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.2889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average Precision</td>\n",
       "      <td>0.5104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric  Mean CV Score\n",
       "0            ROC-AUC         0.9120\n",
       "1           Accuracy         0.9464\n",
       "2          Precision         0.8079\n",
       "3             Recall         0.1775\n",
       "4           F1-Score         0.2889\n",
       "5  Average Precision         0.5104"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_base = run_svm_experiment(\n",
    "    X_sub, y_sub, preprocessing_pipeline, param_grid, sampling_strategy=None, title_suffix=\"Baseline\", class_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87633245",
   "metadata": {},
   "source": [
    "### 2.4 Weighted Loss (Class Weight = 'Balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b332b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Grid Search for Balanced...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "ðŸ”¹ Best Parameters (Balanced): {'svm__C': 1, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "\n",
      "--- PERFORMANCE REPORT (Balanced) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>0.9271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.8338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.2563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.8774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average Precision</td>\n",
       "      <td>0.5320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric  Mean CV Score\n",
       "0            ROC-AUC         0.9271\n",
       "1           Accuracy         0.8338\n",
       "2          Precision         0.2563\n",
       "3             Recall         0.8774\n",
       "4           F1-Score         0.3965\n",
       "5  Average Precision         0.5320"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_weighted = run_svm_experiment(\n",
    "    X_sub, y_sub, preprocessing_pipeline, param_grid, sampling_strategy=None, title_suffix=\"Balanced\", class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d749dfb7",
   "metadata": {},
   "source": [
    "### 2.5 UnderSampling 1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f897d906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Grid Search for UnderSampling 1:1...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "ðŸ”¹ Best Parameters (UnderSampling 1:1): {'svm__C': 1, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "\n",
      "--- PERFORMANCE REPORT (UnderSampling 1:1) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>0.9239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.7762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.2054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.9032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.3344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average Precision</td>\n",
       "      <td>0.5067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric  Mean CV Score\n",
       "0            ROC-AUC         0.9239\n",
       "1           Accuracy         0.7762\n",
       "2          Precision         0.2054\n",
       "3             Recall         0.9032\n",
       "4           F1-Score         0.3344\n",
       "5  Average Precision         0.5067"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_1to1 = run_svm_experiment(\n",
    "    X_sub, y_sub, preprocessing_pipeline, param_grid, sampling_strategy=1.0, title_suffix=\"UnderSampling 1:1\", class_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60440c92",
   "metadata": {},
   "source": [
    "### 2.6 UnderSampling 2:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7e5de2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Grid Search for UnderSampling 2:1...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "ðŸ”¹ Best Parameters (UnderSampling 2:1): {'svm__C': 100, 'svm__gamma': 0.001, 'svm__kernel': 'rbf'}\n",
      "\n",
      "--- PERFORMANCE REPORT (UnderSampling 2:1) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>0.9247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.8886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.3332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.7935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.4693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average Precision</td>\n",
       "      <td>0.5227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric  Mean CV Score\n",
       "0            ROC-AUC         0.9247\n",
       "1           Accuracy         0.8886\n",
       "2          Precision         0.3332\n",
       "3             Recall         0.7935\n",
       "4           F1-Score         0.4693\n",
       "5  Average Precision         0.5227"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_2to1 = run_svm_experiment(\n",
    "    X_sub, y_sub, preprocessing_pipeline, param_grid, sampling_strategy=0.5, title_suffix=\"UnderSampling 2:1\", class_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8799d3a",
   "metadata": {},
   "source": [
    "### 2.7 UnderSampling 10:3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76ad5f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Grid Search for UnderSampling 10:3...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "ðŸ”¹ Best Parameters (UnderSampling 10:3): {'svm__C': 10, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "\n",
      "--- PERFORMANCE REPORT (UnderSampling 10:3) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>0.9256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.9236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.4310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.6710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.5230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average Precision</td>\n",
       "      <td>0.5270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric  Mean CV Score\n",
       "0            ROC-AUC         0.9256\n",
       "1           Accuracy         0.9236\n",
       "2          Precision         0.4310\n",
       "3             Recall         0.6710\n",
       "4           F1-Score         0.5230\n",
       "5  Average Precision         0.5270"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_10to3 = run_svm_experiment(\n",
    "    X_sub, y_sub, preprocessing_pipeline, param_grid, sampling_strategy=0.3, title_suffix=\"UnderSampling 10:3\", class_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffbba4b",
   "metadata": {},
   "source": [
    "### 2.8 UnderSampling 5:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7afdd10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Grid Search for UnderSampling 5:1...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "ðŸ”¹ Best Parameters (UnderSampling 5:1): {'svm__C': 100, 'svm__gamma': 0.001, 'svm__kernel': 'rbf'}\n",
      "\n",
      "--- PERFORMANCE REPORT (UnderSampling 5:1) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>0.9233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.9358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.4887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.5646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.5223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average Precision</td>\n",
       "      <td>0.5300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric  Mean CV Score\n",
       "0            ROC-AUC         0.9233\n",
       "1           Accuracy         0.9358\n",
       "2          Precision         0.4887\n",
       "3             Recall         0.5646\n",
       "4           F1-Score         0.5223\n",
       "5  Average Precision         0.5300"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_5to1= run_svm_experiment(\n",
    "    X_sub, y_sub, preprocessing_pipeline, param_grid, sampling_strategy=0.2, title_suffix=\"UnderSampling 5:1\", class_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb83566",
   "metadata": {},
   "source": [
    "### 2.9 UnderSampling 2:1 + Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16a82e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Grid Search for UnderSampling 2:1 + Balanced...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "ðŸ”¹ Best Parameters (UnderSampling 2:1 + Balanced): {'svm__C': 1, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "\n",
      "--- PERFORMANCE REPORT (UnderSampling 2:1 + Balanced) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>0.9260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.8058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.2298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.3658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average Precision</td>\n",
       "      <td>0.5114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric  Mean CV Score\n",
       "0            ROC-AUC         0.9260\n",
       "1           Accuracy         0.8058\n",
       "2          Precision         0.2298\n",
       "3             Recall         0.9000\n",
       "4           F1-Score         0.3658\n",
       "5  Average Precision         0.5114"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_2to1_weighted = run_svm_experiment(\n",
    "    X_sub, y_sub, preprocessing_pipeline, param_grid, sampling_strategy=0.5, title_suffix=\"UnderSampling 2:1 + Balanced\", class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a47ff0",
   "metadata": {},
   "source": [
    "### 2.10 UnderSampling 5:1 + Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "786de5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Grid Search for UnderSampling 5:1 + Balanced...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "ðŸ”¹ Best Parameters (UnderSampling 5:1 + Balanced): {'svm__C': 1, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "\n",
      "--- PERFORMANCE REPORT (UnderSampling 5:1 + Balanced) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>0.9281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.8236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.2477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.8935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.3873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average Precision</td>\n",
       "      <td>0.5233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric  Mean CV Score\n",
       "0            ROC-AUC         0.9281\n",
       "1           Accuracy         0.8236\n",
       "2          Precision         0.2477\n",
       "3             Recall         0.8935\n",
       "4           F1-Score         0.3873\n",
       "5  Average Precision         0.5233"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_5to1_weighted = run_svm_experiment(\n",
    "    X_sub, y_sub, preprocessing_pipeline, param_grid, sampling_strategy=0.2, title_suffix=\"UnderSampling 5:1 + Balanced\", class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701ba117",
   "metadata": {},
   "source": [
    "## 3. Experimental Results & Model Selection\n",
    "\n",
    "**Best Model: UnderSampling 5:1**\n",
    "\n",
    "The moderate undersampling strategy (reducing the majority class to a 5:1 ratio) yielded the strongest performance.\n",
    "\n",
    "*   **Average Precision: ~0.53** (Best)\n",
    "*   **F1-Score: ~0.52**\n",
    "*   **ROC-AUC: ~0.92**\n",
    "*   **Accuracy: ~0.93**\n",
    "*   **Precision: ~0.48**\n",
    "*   **Recall: ~`0.56**\n",
    "\n",
    "\n",
    "**Optimal Configuration:**\n",
    "The Grid Search identified the following best hyperparameters for this strategy:\n",
    "*   **Kernel:** `'rbf'`\n",
    "*   **C:** `100`\n",
    "*   **Gamma:** `0.001`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6056ef1",
   "metadata": {},
   "source": [
    "## 4. Analysis of Suboptimal Model Performance\n",
    "\n",
    "Despite hyperparameter tuning, the Average Precision and F1 score fails to exceed 0.55. This section investigates the potential root causes of this underperformance, including:\n",
    "- **Data Complexity:** The dataset may lack clear separability or contain high noise levels.\n",
    "- **Model Limitations:** SVMs might not be the optimal algorithm for this specific feature space.\n",
    "- **Preprocessing Issues:** Potential information loss or artifacts introduced during feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9536c49",
   "metadata": {},
   "source": [
    "### 4.1 Training on a Larger Dataset & Threshold Tuning\n",
    "We retrain the model on 50k samples and utilize a separate 10k hold-out validation set to optimize the decision threshold. This separation prevents data leakage. Finally, we compare the Training vs. Validation F1 scores. We specifically monitor the training metrics to verify if high performance is achievable at all. Low training scores would suggest that the data itself lacks sufficient signal or separability, or that the preprocessing pipeline is suboptimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e12472fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset size: (50000, 41)\n",
      "Class distribution in subset:\n",
      "0   0.9379\n",
      "1   0.0621\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_bigger_sub, X_rest, y_bigger_sub, y_rest = train_test_split(\n",
    "    X_train, y_train, \n",
    "    train_size=50000, \n",
    "    stratify=y_train,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_validate, X_rest, y_validate, y_rest = train_test_split(\n",
    "    X_rest, y_rest, \n",
    "    train_size=10000, \n",
    "    stratify=y_rest,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Subset size: {X_bigger_sub.shape}\")\n",
    "print(f\"Class distribution in subset:\\n{pd.Series(y_bigger_sub).value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ca60b7",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7df9c99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_threshold_tuning(model, X_train, y_train, X_val, y_val, verbose=True):\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Calculating probabilities...\")\n",
    "        \n",
    "    y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "    y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_val, y_val_proba)\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "    f1_scores = np.nan_to_num(f1_scores) \n",
    "\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n",
    "    \n",
    "    y_train_pred = (y_train_proba >= best_threshold).astype(int)\n",
    "    y_val_pred = (y_val_proba >= best_threshold).astype(int)\n",
    "\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    val_f1 = f1_score(y_val, y_val_pred)\n",
    "    diff = train_f1 - val_f1\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nOptimal Threshold Found: {best_threshold:.4f}\")\n",
    "        print(\"\\n--- DIAGNOSTICS (Train vs Validation) ---\")\n",
    "        print(f\"Train F1 Score:       {train_f1:.4f}\")\n",
    "        print(f\"Validation F1 Score:  {val_f1:.4f}\")\n",
    "        print(f\"Difference (Overfit): {diff:.4f}\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f57010a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Grid Search for UnderSampling 5:1...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "ðŸ”¹ Best Parameters (UnderSampling 5:1): {'svm__C': 10, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "\n",
      "--- PERFORMANCE REPORT (UnderSampling 5:1) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>0.9151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.9425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.5336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.5794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.5555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average Precision</td>\n",
       "      <td>0.5817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric  Mean CV Score\n",
       "0            ROC-AUC         0.9151\n",
       "1           Accuracy         0.9425\n",
       "2          Precision         0.5336\n",
       "3             Recall         0.5794\n",
       "4           F1-Score         0.5555\n",
       "5  Average Precision         0.5817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model_bigger_set = run_svm_experiment(\n",
    "    X_bigger_sub, y_bigger_sub, preprocessing_pipeline, param_grid, sampling_strategy=0.2, title_suffix=\"UnderSampling 5:1\", class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dd8cc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating probabilities...\n",
      "\n",
      "Optimal Threshold Found: 0.5065\n",
      "\n",
      "--- DIAGNOSTICS (Train vs Validation) ---\n",
      "Train F1 Score:       0.5767\n",
      "Validation F1 Score:  0.5723\n",
      "Difference (Overfit): 0.0044\n"
     ]
    }
   ],
   "source": [
    "evaluate_with_threshold_tuning(best_model_bigger_set, X_bigger_sub, y_bigger_sub, X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45168d10",
   "metadata": {},
   "source": [
    "### Performance Analysis:\n",
    "F1-score remains low (~0.57) even after threshold tuning. Crucially, the Training and Validation scores are nearly identical, with a difference of almost zero.\n",
    "\n",
    "Optimal Threshold is ~0.5 which indicates no threshold tuning is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d487440",
   "metadata": {},
   "source": [
    "### 4.2 Alternative Model - XGBoost\n",
    "To verify whether the performance bottleneck is intrinsic to the dataset or a limitation of the Support Vector Machine (SVM) algorithm, we train an XGBoost classifier. As a tree-based ensemble method, XGBoost handles non-linear relationships and feature interactions differently than SVMs, potentially uncovering patterns the previous model missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "647a5fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Randomized Search...\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "\n",
      "ðŸ”¹ Best Parameters: {'classifier__subsample': 0.9, 'classifier__n_estimators': 500, 'classifier__min_child_weight': 3, 'classifier__max_depth': 6, 'classifier__learning_rate': 0.03, 'classifier__gamma': 1.0, 'classifier__colsample_bytree': 0.7}\n",
      "\n",
      "--- PERFORMANCE REPORT ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>0.9439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.8797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.3214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.8434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.4654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average Precision</td>\n",
       "      <td>0.6260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric  Mean CV Score\n",
       "0            ROC-AUC         0.9439\n",
       "1           Accuracy         0.8797\n",
       "2          Precision         0.3214\n",
       "3             Recall         0.8434\n",
       "4           F1-Score         0.4654\n",
       "5  Average Precision         0.6260"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_neg = len(y_bigger_sub) - y_bigger_sub.sum()\n",
    "count_pos = y_bigger_sub.sum()\n",
    "scale_ratio = count_neg / count_pos\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline), \n",
    "    ('classifier', XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        scale_pos_weight=scale_ratio,\n",
    "        n_jobs=-1,\n",
    "        tree_method='hist' \n",
    "    ))\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': [500, 1000],\n",
    "    'classifier__learning_rate': [0.03, 0.05, 0.1],\n",
    "    'classifier__max_depth': [4, 6, 8], \n",
    "    'classifier__min_child_weight': [1, 3, 5],\n",
    "    'classifier__colsample_bytree': [0.6, 0.7, 0.8], \n",
    "    'classifier__subsample': [0.7, 0.8, 0.9],\n",
    "    'classifier__gamma': [0.1, 0.5, 1.0] \n",
    "}\n",
    "\n",
    "scoring_metrics = {\n",
    "    'ROC-AUC': 'roc_auc',\n",
    "    'Accuracy': 'accuracy',\n",
    "    'Precision': 'precision',\n",
    "    'Recall': 'recall',\n",
    "    'F1-Score': 'f1',\n",
    "    'Average Precision': 'average_precision'\n",
    "}\n",
    "\n",
    "best_model_xg = RandomizedSearchCV(\n",
    "    full_pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=15, \n",
    "    scoring=scoring_metrics,\n",
    "    refit='Average Precision',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Running Randomized Search...\")\n",
    "best_model_xg.fit(X_bigger_sub, y_bigger_sub)\n",
    "\n",
    "print(f\"\\nðŸ”¹ Best Parameters: {best_model_xg.best_params_}\")\n",
    "print(\"\\n--- PERFORMANCE REPORT ---\\n\")\n",
    "\n",
    "results = []\n",
    "best_index = best_model_xg.best_index_\n",
    "\n",
    "for metric_name in scoring_metrics.keys():\n",
    "    mean_score = best_model_xg.cv_results_[f'mean_test_{metric_name}'][best_index]\n",
    "    results.append({\n",
    "        'Metric': metric_name, \n",
    "        'Mean CV Score': round(mean_score, 4)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2cf2b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating probabilities...\n",
      "\n",
      "Optimal Threshold Found: 0.7924\n",
      "\n",
      "--- DIAGNOSTICS (Train vs Validation) ---\n",
      "Train F1 Score:       0.6413\n",
      "Validation F1 Score:  0.5965\n",
      "Difference (Overfit): 0.0448\n"
     ]
    }
   ],
   "source": [
    "evaluate_with_threshold_tuning(best_model_xg, X_bigger_sub, y_bigger_sub, X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3342b44",
   "metadata": {},
   "source": [
    "### Performance Analysis\n",
    "\n",
    "Even with XGBoost, the F1 score remains suboptimal (~0.59 on validation, ~0.64 on train). Since two fundamentally different algorithms (Linear/Kernel SVM and Gradient Boosting) failed to achieve high performance, we can conclude that the issue is not the choice of model.\n",
    "\n",
    "\n",
    "**Hypothesized Root Causes:**\n",
    "- **Aggressive Preprocessing:** The feature engineering steps (e.g., grouping industries/occupations may have discarded critical signal, leading to information loss\n",
    "- **Low Separability:** The dataset itself may contain high noise or overlapping classes, making it impossible to separate them with high precision based on the available features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f09b43",
   "metadata": {},
   "source": [
    "### 4.3 Soft Pipeline\n",
    "\n",
    "To investigate if the previous feature engineering was too aggressive (causing information loss), we implemented a \"Soft\" pipeline with the following adjustments:\n",
    "\n",
    "- **Financial Features Preserved:** `capital_gains` and `capital_losses` are retained and log-transformed instead of being dropped in favor of just `net_capital`\n",
    "- **Raw Categories Kept:** Removed broad manual grouping for `major_ind_code` and `major_occ_code`. These are now one-hot encoded with `min_frequency=0.01` to handle cardinality automatically while preserving detail\n",
    "- **Otherwise Identical:** All other preprocessing steps (cleaning, scaling, and other engineered features) remain exactly the same as in the primary pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6619154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Grid Search for UnderSampling 5:1...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "ðŸ”¹ Best Parameters (UnderSampling 5:1): {'svm__C': 100, 'svm__gamma': 0.001, 'svm__kernel': 'rbf'}\n",
      "\n",
      "--- PERFORMANCE REPORT (UnderSampling 5:1) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>0.9398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.9410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.5219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.5988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.5577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average Precision</td>\n",
       "      <td>0.5903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric  Mean CV Score\n",
       "0            ROC-AUC         0.9398\n",
       "1           Accuracy         0.9410\n",
       "2          Precision         0.5219\n",
       "3             Recall         0.5988\n",
       "4           F1-Score         0.5577\n",
       "5  Average Precision         0.5903"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model_bigger_set_soft_pipeline = run_svm_experiment(\n",
    "    X_bigger_sub, y_bigger_sub, soft_preprocessing_pipeline, param_grid, sampling_strategy=0.2, title_suffix=\"UnderSampling 5:1\", class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e794194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating probabilities...\n",
      "\n",
      "Optimal Threshold Found: 0.5250\n",
      "\n",
      "--- DIAGNOSTICS (Train vs Validation) ---\n",
      "Train F1 Score:       0.5735\n",
      "Validation F1 Score:  0.5672\n",
      "Difference (Overfit): 0.0062\n"
     ]
    }
   ],
   "source": [
    "evaluate_with_threshold_tuning(best_model_bigger_set_soft_pipeline, X_bigger_sub, y_bigger_sub, X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f618ece5",
   "metadata": {},
   "source": [
    "### Performance Analysis: Soft Pipeline\n",
    "Comparing the \"Soft\" pipeline to the previous approach, we observe the following performance metrics:\n",
    "\n",
    "**1. Cross-Validation (Mean CV Score):**\n",
    "*   **F1-Score:** Remained stable at **0.56**\n",
    "*   **Average Precision:** Increased from **0.58** to **0.59**\n",
    "\n",
    "**2. Validation Set (Hold-out):**\n",
    "*   **F1-Score:** Remained consistent at **0.57**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f34293",
   "metadata": {},
   "source": [
    "### 4.4 Unethical Pipeline\n",
    "To rigorously test the performance limitations, we implemented an \"Unethical\" pipeline. This setup builds directly upon the **Soft Pipeline** strategy (preserving financial details and raw categories) but deliberately **reintroduces sensitive demographic features**: `sex`, `race`, and `hisp_origin`.\n",
    "\n",
    "Optimal Threshold is ~0.5 which indicates no threshold tuning is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "634e286c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Grid Search for UnderSampling 5:1...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "ðŸ”¹ Best Parameters (UnderSampling 5:1): {'svm__C': 1, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "\n",
      "--- PERFORMANCE REPORT (UnderSampling 5:1) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>0.9427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.9441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.5461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.5897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.5671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average Precision</td>\n",
       "      <td>0.6106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric  Mean CV Score\n",
       "0            ROC-AUC         0.9427\n",
       "1           Accuracy         0.9441\n",
       "2          Precision         0.5461\n",
       "3             Recall         0.5897\n",
       "4           F1-Score         0.5671\n",
       "5  Average Precision         0.6106"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model_bigger_set_unethical_pipeline = run_svm_experiment(\n",
    "    X_bigger_sub, y_bigger_sub, unethical_preprocessing_pipeline, param_grid, sampling_strategy=0.2, title_suffix=\"UnderSampling 5:1\", class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b5297a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating probabilities...\n",
      "\n",
      "Optimal Threshold Found: 0.5690\n",
      "\n",
      "--- DIAGNOSTICS (Train vs Validation) ---\n",
      "Train F1 Score:       0.5763\n",
      "Validation F1 Score:  0.5928\n",
      "Difference (Overfit): -0.0165\n"
     ]
    }
   ],
   "source": [
    "evaluate_with_threshold_tuning(best_model_bigger_set_unethical_pipeline, X_bigger_sub, y_bigger_sub, X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1517e3c7",
   "metadata": {},
   "source": [
    "### Performance Analysis: Unethical Pipeline\n",
    "Comparing the \"Unethical\" pipeline (which reintroduces sensitive demographic features) to the \"Soft\" pipeline, we observe a clear performance boost, confirming that demographic variables hold significant predictive power:\n",
    "\n",
    "**1. Cross-Validation (Mean CV Score):**\n",
    "*   **F1-Score:** Increased from **0.56** to **0.57**\n",
    "*   **Average Precision:** Rose from **0.59** to **0.61**\n",
    "\n",
    "**2. Validation Set (Hold-out):**\n",
    "*   **F1-Score:** Improved from **0.57** to **0.59**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c67c36",
   "metadata": {},
   "source": [
    "### 4.5 More Features Pipeline\n",
    "In this step, we extend the \"Unethical\" pipeline by re-introducing specific auxiliary features that were previously dropped: `own_or_self`, `vet_benefits`, `unemp_reason`, and `vet_question`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "deafe785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Grid Search for UnderSampling 5:1...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "ðŸ”¹ Best Parameters (UnderSampling 5:1): {'svm__C': 1, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "\n",
      "--- PERFORMANCE REPORT (UnderSampling 5:1) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>0.9427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.9443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.5478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.5878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.5671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average Precision</td>\n",
       "      <td>0.6100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric  Mean CV Score\n",
       "0            ROC-AUC         0.9427\n",
       "1           Accuracy         0.9443\n",
       "2          Precision         0.5478\n",
       "3             Recall         0.5878\n",
       "4           F1-Score         0.5671\n",
       "5  Average Precision         0.6100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model_bigger_set_more_features_pipeline = run_svm_experiment(\n",
    "    X_bigger_sub, y_bigger_sub, more_features_preprocessing_pipeline, param_grid, sampling_strategy=0.2, title_suffix=\"UnderSampling 5:1\", class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b48314d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating probabilities...\n",
      "\n",
      "Optimal Threshold Found: 0.5823\n",
      "\n",
      "--- DIAGNOSTICS (Train vs Validation) ---\n",
      "Train F1 Score:       0.5781\n",
      "Validation F1 Score:  0.5912\n",
      "Difference (Overfit): -0.0130\n"
     ]
    }
   ],
   "source": [
    "evaluate_with_threshold_tuning(best_model_bigger_set_more_features_pipeline, X_bigger_sub, y_bigger_sub, X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f2fc0a",
   "metadata": {},
   "source": [
    "### Performance Analysis: More Features Pipeline\n",
    "Comparing the \"More Features\" pipeline (adding auxiliary features like `vet_benefits`) to the \"Unethical\" pipeline, we observe that the additional complexity did not yield performance gains, suggesting these features contain little incremental predictive value:\n",
    "\n",
    "**1. Cross-Validation (Mean CV Score):**\n",
    "*   **F1-Score:** Remained stable at **0.57**\n",
    "*   **Average Precision:** Remained constant at **0.61**\n",
    "\n",
    "**2. Validation Set (Hold-out):**\n",
    "*   **F1-Score:** Remained consistent at **0.59**\n",
    "\n",
    "\n",
    "Optimal Threshold is ~0.58 which indicates slight threshold tuning is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c653178",
   "metadata": {},
   "source": [
    "### 4.6 Very Soft Pipeline\n",
    "In this final configuration, we aim to maximize the information available to the model by combining manual engineering with raw data retention:\n",
    "\n",
    "*   **Create but Don't Delete:** We generate all our new synthetic features (e.g., `net_capital`, `is_investor`), but unlike previous pipelines, we **do not remove any original columns**. Both the derived features and their raw sources are passed to the model.\n",
    "*   **No Manual Grouping:** We completely skip the manual categorization step (e.g., grouping industries or employment status). Instead, we use `OneHotEncoder` with a very low **`min_frequency=0.001`**, allowing the model to see virtually all original, granular categories.\n",
    "*   **Automated Selection:** Since this approach generates a huge number of features (often redundant), we add a **`SelectKBest(k=100)`** step at the end. This forces the algorithm to automatically pick the 100 most predictive features from this massive pool of engineered and raw variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2193a85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Grid Search for UnderSampling 5:1...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "ðŸ”¹ Best Parameters (UnderSampling 5:1): {'svm__C': 10, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "\n",
      "--- PERFORMANCE REPORT (UnderSampling 5:1) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>0.9275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.9422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.5296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.6133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.5684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average Precision</td>\n",
       "      <td>0.6093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric  Mean CV Score\n",
       "0            ROC-AUC         0.9275\n",
       "1           Accuracy         0.9422\n",
       "2          Precision         0.5296\n",
       "3             Recall         0.6133\n",
       "4           F1-Score         0.5684\n",
       "5  Average Precision         0.6093"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model_bigger_set_very_soft_pipeline = run_svm_experiment(\n",
    "    X_bigger_sub, y_bigger_sub, very_soft_preprocessing_pipeline, param_grid, sampling_strategy=0.2, title_suffix=\"UnderSampling 5:1\", class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2821939e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating probabilities...\n",
      "\n",
      "Optimal Threshold Found: 0.5852\n",
      "\n",
      "--- DIAGNOSTICS (Train vs Validation) ---\n",
      "Train F1 Score:       0.6033\n",
      "Validation F1 Score:  0.5937\n",
      "Difference (Overfit): 0.0096\n"
     ]
    }
   ],
   "source": [
    "evaluate_with_threshold_tuning(best_model_bigger_set_very_soft_pipeline, X_bigger_sub, y_bigger_sub, X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5918272a",
   "metadata": {},
   "source": [
    "### Performance Analysis: Very Soft Pipeline\n",
    "Comparing the \"Very Soft\" pipeline (which utilizes granular raw data and automated `SelectKBest` feature selection) to the previous \"More Features\" pipeline, we observe that performance has reached a plateau. This indicates that the automated selection strategy successfully identified the predictive signals matched by the previous approach but did not uncover additional information:\n",
    "\n",
    "**1. Cross-Validation (Mean CV Score):**\n",
    "*   **F1-Score:** Remained stable at **0.57**\n",
    "*   **Average Precision:** Remained consistent at **0.61**\n",
    "\n",
    "**2. Validation Set (Hold-out):**\n",
    "*   **F1-Score:** Remained stable at **0.59**\n",
    "\n",
    "Optimal Threshold is ~0.58 which indicates slight threshold tuning is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c93fb0",
   "metadata": {},
   "source": [
    "### 4.7 Conclusion\n",
    "\n",
    "After testing multiple preprocessing strategies and feature sets, we arrived at the following conclusions:\n",
    "\n",
    "**1. Pipeline Evaluation:**\n",
    "*   **\"Soft\" Pipeline is the Optimal Balance:** While the \"Very Soft\" and \"Unethical\" pipelines achieved the highest raw metrics (Validation F1 ~0.59), the **Soft Pipeline** (Validation F1 ~0.57) remains the superior choice for production. It offers an improvement over the baseline without relying on sensitive demographic data or unmanageable feature spaces.\n",
    "*   **The Ethical Trade-off:** Reintroducing protected attributes (`sex`, `race`) in the \"Unethical Pipeline\" **improved performance** (F1 rose from 0.57 to 0.59). This confirms that demographic bias exists in the dataset and has predictive power. However, we explicitly **reject** this gain to adhere to fairness constraints and prevent the model from perpetuating historical biases.\n",
    "*   **Automation vs. Manual Engineering:** The \"Very Soft\" pipeline, which used automated feature selection (`SelectKBest`) on raw data, matched the performance of our manually engineered pipelines. This proves that while automated selection is effective, it hit the same \"performance ceiling,\" suggesting no hidden signal was missed by our manual feature engineering.\n",
    "\n",
    "**2. Root Cause Analysis:**\n",
    "*   **Intrinsic Data Difficulty:** The performance plateau around **F1 ~0.59** (even with all features and raw data) indicates a limit in the data's separability. Since more complex non-linear methods (like XGBoost tested in parallel) also struggled to break this ceiling, we conclude the bottleneck is the **class overlap** in the dataset, not the SVM architecture itself.\n",
    "\n",
    "**Final Verdict:**\n",
    "We select the **Soft Preprocessing Pipeline**. It maximizes predictive capability (~0.57 F1) while maintaining strict ethical standards and model interpretability, accepting a minor trade-off in performance to ensure a fair and unbiased model. Also no threshold tuning is needed.\n",
    "\n",
    "**Optimal Model Configuration:**\n",
    "*   **Kernel:** RBF\n",
    "*   **C:** 100\n",
    "*   **Gamma:** 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9343075a",
   "metadata": {},
   "source": [
    "## 5. Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aec2d6a",
   "metadata": {},
   "source": [
    "### 5.1 Initial Optimization\n",
    "Based on previous experiments where the optimal parameters hit the edge of the grid (`C=100`, `gamma=0.001`), we now perform a focused search around these values. We utilize the same 50k training subset to maintain consistency, but with a denser grid to pinpoint the absolute global maximum for `C` and `gamma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d2b3dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Grid Search for Initial Optimization...\n",
      "Fitting 3 folds for each of 56 candidates, totalling 168 fits\n",
      "\n",
      "ðŸ”¹ Best Parameters (Initial Optimization): {'svm__C': 500, 'svm__gamma': 0.0008, 'svm__kernel': 'rbf'}\n",
      "\n",
      "--- PERFORMANCE REPORT (Initial Optimization) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>0.9396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.9408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.5196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.6062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.5596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average Precision</td>\n",
       "      <td>0.6004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric  Mean CV Score\n",
       "0            ROC-AUC         0.9396\n",
       "1           Accuracy         0.9408\n",
       "2          Precision         0.5196\n",
       "3             Recall         0.6062\n",
       "4           F1-Score         0.5596\n",
       "5  Average Precision         0.6004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_grid_initial_optimization = [\n",
    "    {\n",
    "    'svm__kernel': ['rbf'],\n",
    "    'svm__C': [50, 80, 100, 150, 200, 500, 1000],\n",
    "    'svm__gamma': [0.0001, 0.0005, 0.0008, 0.001, 0.0015, 0.002, 0.003, 0.004]\n",
    "    }\n",
    "]\n",
    "initial_opitimization_model = run_svm_experiment(\n",
    "    X_bigger_sub, y_bigger_sub, soft_preprocessing_pipeline, param_grid_initial_optimization, sampling_strategy=0.2, title_suffix=\"Initial Optimization\", class_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9ede1d",
   "metadata": {},
   "source": [
    "### 5.2 Extended Hyperparameter Tuning\n",
    "Full Dataset Optimization & Micro-Tuning\n",
    "Having identified the optimal region (`C=500`, `gamma=0.0008`) on the subset, we now scale up the training to the entire dataset. We perform a very narrow grid search centered around these values to finalize the model hyperparameters, ensuring they are tuned specifically for the full data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "926616ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Grid Search for Extended Optimization...\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "\n",
      "ðŸ”¹ Best Parameters (Extended Optimization): {'svm__C': 800, 'svm__gamma': 0.0009, 'svm__kernel': 'rbf'}\n",
      "\n",
      "--- PERFORMANCE REPORT (Extended Optimization) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>0.9297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.9430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.5358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.6095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.5703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average Precision</td>\n",
       "      <td>0.6024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric  Mean CV Score\n",
       "0            ROC-AUC         0.9297\n",
       "1           Accuracy         0.9430\n",
       "2          Precision         0.5358\n",
       "3             Recall         0.6095\n",
       "4           F1-Score         0.5703\n",
       "5  Average Precision         0.6024"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_grid_extended_optimization = [\n",
    "    {\n",
    "    'svm__kernel': ['rbf'],\n",
    "    'svm__C': [350, 500, 650, 800],\n",
    "    'svm__gamma': [0.0007, 0.0008, 0.0009]\n",
    "    }\n",
    "]\n",
    "extended_optimization_model = run_svm_experiment(\n",
    "    X_train, y_train, soft_preprocessing_pipeline, param_grid_extended_optimization, sampling_strategy=0.2, title_suffix=\"Extended Optimization\", class_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a2b1a0",
   "metadata": {},
   "source": [
    "## 6. The Best Model\n",
    "\n",
    "After an experimental process we have identified the optimal configuration for predicting high-income individuals in this highly imbalanced dataset.\n",
    "\n",
    "**Final Configuration:**\n",
    "*   **Algorithm:** Support Vector Machine (SVM)\n",
    "*   **Kernel:** `'rbf'`\n",
    "*   **Regularization (C):** `800`\n",
    "*   **Gamma:** `0.0009`\n",
    "*   **Imbalance Strategy:** Random UnderSampling (5:1 ratio / `sampling_strategy=0.2`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048f31e9",
   "metadata": {},
   "source": [
    "## 7. Saving Final Model to the File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad1e5d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Final trained model successfully saved to 'final_model.pkl'\n",
      "This model was trained on X_train/y_train using the optimal parameters found.\n"
     ]
    }
   ],
   "source": [
    "final_trained_model = extended_optimization_model\n",
    "\n",
    "model_filename = 'final_model.pkl'\n",
    "\n",
    "try:\n",
    "    with open(model_filename, 'wb') as file:\n",
    "        pickle.dump(final_trained_model, file)\n",
    "    print(f\"\\n Final trained model successfully saved to '{model_filename}'\")\n",
    "    print(\"This model was trained on X_train/y_train using the optimal parameters found.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n Error saving the model: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
